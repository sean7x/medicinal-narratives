{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-validation Workbook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Load libraries and Defining fuctions for each stage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import html\n",
    "\n",
    "# Import and initialize tqdm for Pandas\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from gensim.models.phrases import Phrases, ENGLISH_CONNECTOR_WORDS\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import TfidfModel\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "import numpy as np\n",
    "\n",
    "from gensim.models import LdaModel, Nmf, CoherenceModel\n",
    "import pyLDAvis\n",
    "\n",
    "# Depress DeprecationWarnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "import os.path\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from dvclive import Live\n",
    "import dvc.api\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 `preprocess(input_path)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(input_path, pct=1, RANDOM_SEED=42):\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "    if input_path.suffix == \".csv\":\n",
    "        df = pd.read_csv(input_path)\n",
    "    elif input_path.suffix == '.jsonl':\n",
    "        df = pd.read_json(input_path, lines=True)\n",
    "    elif input_path.suffix == '.parquet':\n",
    "        df = pd.read_parquet(input_path)\n",
    "    elif input_path.suffix == '.feather':\n",
    "        df = pd.read_feather(input_path)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown file type: {input_path.suffix}\")\n",
    "    \n",
    "    # Extract a subset of the data\n",
    "    if pct < 1:\n",
    "        df = df.sample(frac=pct, random_state=RANDOM_SEED)\n",
    "    \n",
    "    # Decode HTML entities back to original characters and remove whitespaces\n",
    "    df['review'] = df['review'].apply(html.unescape).str.replace(r'[\\r\\n\\t]', '', regex=True).str.strip()\n",
    "\n",
    "    # Remove wrong condition values and keep the rows\n",
    "    df.loc[df.condition.notna() & df.condition.str.contains('users found this comment helpful'), 'condition'] = None\n",
    "    \n",
    "    # Remove rows with empty reviews\n",
    "    df = df[df['review'].notna()]\n",
    "    df = df[df['review'] != '\"-\"']\n",
    "    df = df[df['review'] != '']\n",
    "\n",
    "    # Generate lemmas for each token, remove stopwords and punctuations\n",
    "    #df['procd_review'] = df['review'].progress_apply(\n",
    "    #    #lambda x: ' '.join([token.lemma_ for token in nlp(x) if not token.is_stop and not token.is_punct])\n",
    "    #    lambda x: [token.lemma_ for token in nlp(x) if not token.is_stop and not token.is_punct]\n",
    "    #)\n",
    "    def lemma(row):\n",
    "        # Skip if review is empty\n",
    "        if pd.isnull(row['review']): return row\n",
    "\n",
    "        # lemma_w_stpwrd: with stop words, for word2vec and bert embeddings\n",
    "        row['lemma_w_stpwrd'] = [token.lemma_ for token in nlp(row['review']) if not (token.is_punct or token.is_space or token.lemma_.strip() == '')]\n",
    "        # lemma_wo_stpwrd: lower without stop words, for BoW and TF-IDF embeddings\n",
    "        row['lemma_wo_stpwrd'] = [token.lemma_.lower() for token in nlp(row['review']) if not (token.is_stop or token.is_punct or token.is_space or token.lemma_.strip() == '')]\n",
    "        \n",
    "        # For reviews with only stop words, use lemma_w_stpwrd\n",
    "        if len(row['lemma_wo_stpwrd']) == 0:\n",
    "            row['lemma_wo_stpwrd'] = row['lemma_w_stpwrd']\n",
    "        return row\n",
    "    \n",
    "    procd_df = df.progress_apply(lemma, axis=1)\n",
    "\n",
    "    return procd_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 `feature_engineering(procd_df, procd_text, ngram, bert, bert_pretrained_model, RANDOM_SEED)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(procd_data, ngram, bert, bert_pretrained_model=None, RANDOM_SEED=42):\n",
    "    # BERT Embeddings\n",
    "    if bert:\n",
    "        tokenizer = BertTokenizer.from_pretrained(bert_pretrained_model)\n",
    "        bert_model = BertModel.from_pretrained(bert_pretrained_model)\n",
    "        # Move model to GPU if available\n",
    "        if torch.cuda.is_available():\n",
    "            device = torch.device('cuda')\n",
    "            torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "            torch.backends.cudnn.deterministic = True\n",
    "        #elif torch.backends.mps.is_available():\n",
    "        #    device = torch.device('mps')\n",
    "        #    torch.mps.manual_seed(RANDOM_SEED)\n",
    "        #    torch.backends.mps.deterministic = True\n",
    "        else:\n",
    "            device = torch.device('cpu')\n",
    "            torch.manual_seed(RANDOM_SEED)\n",
    "            torch.backends.cudnn.deterministic = True\n",
    "\n",
    "        bert_model = bert_model.to(device)\n",
    "        print(f\"Using device: {device}\")\n",
    "    \n",
    "        def get_bert_embeddings(text):\n",
    "            inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True)\n",
    "            # Move inputs to GPU if available\n",
    "            if device.type != 'cpu':\n",
    "                inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "\n",
    "            outputs = bert_model(**inputs)\n",
    "            return outputs.last_hidden_state.mean(dim=1)\n",
    "        \n",
    "        bert_embeddings = [\n",
    "            get_bert_embeddings(doc).cpu().detach().numpy() for doc in tqdm(procd_data, desc='Generating BERT Embeddings')\n",
    "        ]\n",
    "    \n",
    "    # Extract BOW and TF-IDF features\n",
    "    # Add bigrams\n",
    "    if ngram == 'bigram':\n",
    "        phrase_model = Phrases(procd_data, min_count=1, threshold=1, connector_words=ENGLISH_CONNECTOR_WORDS)\n",
    "        procd_data_bigram = procd_data.progress_apply(lambda x: phrase_model[x])\n",
    "\n",
    "        dictionary = Dictionary(procd_data_bigram)\n",
    "    elif ngram == 'unigram':\n",
    "        dictionary = Dictionary(procd_data)\n",
    "\n",
    "    # BoW\n",
    "    bow_corpus = [dictionary.doc2bow(doc) for doc in tqdm(procd_data, desc='Generating BoW')]\n",
    "\n",
    "    # TF-IDF\n",
    "    tfidf_model = TfidfModel(bow_corpus)\n",
    "    tfidf_corpus = [tfidf_model[doc] for doc in tqdm(bow_corpus, desc='Generating TF-IDF')]\n",
    "    \n",
    "    return len(procd_data), bert_embeddings if bert else None, procd_data_bigram if ngram == 'bigram' else None, dictionary, bow_corpus, tfidf_corpus\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 `clustering(bert_embeddings, algorithm, num_clusters, RANDOM_SEED)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering(bert_embeddings, algorithm, num_clusters, RANDOM_SEED):\n",
    "    \"\"\"\n",
    "    Cluster the input data using the specified algorithm and number of clusters.\n",
    "    \"\"\"\n",
    "    # Prepare the input data for clustering\n",
    "    bert_embedding_avg = [np.mean(embedding, axis=0) for embedding in bert_embeddings]\n",
    "    input_data = np.vstack(bert_embedding_avg)\n",
    "\n",
    "    # Scale the input data\n",
    "    scaler = StandardScaler()\n",
    "    input_data = scaler.fit_transform(input_data)\n",
    "\n",
    "    # Initialize clustering algorithm\n",
    "    if algorithm == 'kmeans':\n",
    "        clustering_model = KMeans(\n",
    "            n_clusters=num_clusters,\n",
    "            n_init='auto',\n",
    "            random_state=RANDOM_SEED,\n",
    "        )\n",
    "    elif algorithm == 'hierarchical':\n",
    "        clustering_model = AgglomerativeClustering(\n",
    "            n_clusters=num_clusters,\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f'Unknown clustering algorithm: {algorithm}')\n",
    "\n",
    "    # Fit the clustering algorithm to the data and get the labels\n",
    "    clustering_model.fit(input_data)\n",
    "    labels = clustering_model.labels_\n",
    "\n",
    "    # Calculate the metrics if possible\n",
    "    if len(set(labels)) > 1:\n",
    "        silhouette = silhouette_score(input_data, labels)\n",
    "        davies_bouldin = davies_bouldin_score(input_data, labels)\n",
    "        calinski_harabasz = calinski_harabasz_score(input_data, labels)\n",
    "    else:\n",
    "        silhouette_avg = davies_bouldin = calinski_harabasz = np.nan\n",
    "\n",
    "    return clustering_model, silhouette, davies_bouldin, calinski_harabasz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5 `topic_modeling(procd_data, corpus, dictionary, algorithm, num_topics, RANDOM_SEED)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_modeling(procd_data, corpus, dictionary, algorithm, num_topics, RANDOM_SEED):\n",
    "    # Set up topic model\n",
    "    # LDA Model\n",
    "    if algorithm == 'lda':\n",
    "        topic_model = LdaModel(\n",
    "            corpus,\n",
    "            num_topics=num_topics,\n",
    "            id2word=dictionary,\n",
    "            random_state=RANDOM_SEED,\n",
    "        )\n",
    "        perplexity = topic_model.log_perplexity(corpus)\n",
    "    \n",
    "    # NMF Model\n",
    "    elif algorithm == 'nmf':\n",
    "        topic_model = Nmf(\n",
    "            corpus,\n",
    "            num_topics=num_topics,\n",
    "            id2word=dictionary,\n",
    "            random_state=RANDOM_SEED,\n",
    "        )\n",
    "        perplexity = None\n",
    "\n",
    "    # Calculate Coherence score\n",
    "    coherence_model = CoherenceModel(\n",
    "        model=topic_model,\n",
    "        texts=procd_data.tolist(),\n",
    "        #corpus=corpus,\n",
    "        dictionary=dictionary,\n",
    "        coherence='c_v',\n",
    "        #coherence='u_mass',\n",
    "        processes=-1\n",
    "    )\n",
    "    coherence = coherence_model.get_coherence()\n",
    "\n",
    "    return topic_model, perplexity, coherence\n",
    "\n",
    "\n",
    "def prepare_topic_model_viz(topic_model, dictionary, corpus):\n",
    "    # Extract the topic-term matrix\n",
    "    topic_term_matrix = topic_model.get_topics()\n",
    "\n",
    "    # Extract the document-topic matrix\n",
    "    num_topics = topic_model.num_topics\n",
    "    doc_topic_matrix = []\n",
    "\n",
    "    for doc in tqdm(topic_model[corpus]):\n",
    "        doc_topics = dict(doc)\n",
    "        doc_topic_vec = [doc_topics.get(i, 0.0) for i in range(num_topics)]\n",
    "        doc_topic_matrix.append(doc_topic_vec)\n",
    "\n",
    "    # Normalize topic_term_matrix and doc_topic_matrix\n",
    "    topic_term_matrix = topic_term_matrix / np.sum(topic_term_matrix, axis=1, keepdims=True)\n",
    "    doc_topic_matrix = doc_topic_matrix / np.sum(doc_topic_matrix, axis=1, keepdims=True)\n",
    "\n",
    "    doc_topic_matrix = np.array(doc_topic_matrix)\n",
    "    \n",
    "    # Vocabulary and term frequencies\n",
    "    vocab = [dictionary[i] for i in range(len(dictionary))]\n",
    "\n",
    "    term_freq = np.zeros(len(vocab))\n",
    "    for doc in corpus:\n",
    "        for idx, freq in doc:\n",
    "            term_freq[idx] += freq\n",
    "    \n",
    "    # Prepare the data in pyLDAvis format\n",
    "    vis_data = pyLDAvis.prepare(\n",
    "        doc_lengths=np.array([sum(dict(doc).values()) for doc in corpus]),\n",
    "        vocab=vocab,\n",
    "        term_frequency=term_freq,\n",
    "        topic_term_dists=topic_term_matrix,\n",
    "        doc_topic_dists=doc_topic_matrix\n",
    "    )\n",
    "\n",
    "    # Return the visualization data\n",
    "    return vis_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.6 `pipeline()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(procd_df, procd_text, ngram, bert_pretrained_model, clustering, clustering_algorithms=None, num_clusters=None, feature='lda', topic_modeling_algorithm='lda', num_topics=8, RANDOM_SEED=42):\n",
    "    # Load preprocessed text data\n",
    "    procd_data = procd_df[procd_text].progress_apply(lambda x: eval(x))\n",
    "    procd_data = procd_data[procd_data.progress_apply(lambda row: len(row) > 0)]\n",
    "    \n",
    "    # Feature engineering\n",
    "    bert = clustering\n",
    "    num_docs, bert_embeddings, procd_data_bigram, dictionary, bow_corpus, tfidf_corpus = feature_engineering(\n",
    "        procd_data,\n",
    "        ngram,\n",
    "        bert,\n",
    "        bert_pretrained_model,\n",
    "        RANDOM_SEED\n",
    "    )\n",
    "\n",
    "    # Clustering\n",
    "    if clustering:\n",
    "        clustering_model, silhouette, davies_bouldin, calinski_harabasz = clustering(\n",
    "            bert_embeddings,\n",
    "            clustering_algorithms,\n",
    "            num_clusters,\n",
    "            RANDOM_SEED\n",
    "        )\n",
    "    \n",
    "    # Topic Modeling\n",
    "    if feature == 'bow': corpus = bow_corpus\n",
    "    elif feature == 'tfidf': corpus = tfidf_corpus\n",
    "    else: raise ValueError(f'Unknown feature: {feature}')\n",
    "\n",
    "    if clustering:\n",
    "        # Add cluster labels to corpus\n",
    "        print(f\"Topic modeling with clustering via Bert {clustering_algorithms}...\")\n",
    "        # Get the all the cluster labels\n",
    "        labels = clustering_model.labels_\n",
    "\n",
    "        # Add cluster labels to the preprocessed text data\n",
    "        grouped_procd_data = pd.DataFrame({'cluster_label': labels, 'procd_text': procd_data_bigram}).groupby('cluster_label')\n",
    "\n",
    "        # Apply LDA to each clustered corpus\n",
    "        topic_models = {}\n",
    "        coherence_scores = {}\n",
    "        perplexity_scores = {}\n",
    "\n",
    "        for label, group in tqdm(grouped_procd_data, desc='Training topic models for each cluster'):\n",
    "            # Extract the clustered corpus and texts\n",
    "            clustered_corpus = [corpus[i] for i in group.index]\n",
    "            clustered_texts = group['procd_text']\n",
    "            \n",
    "            # Train the topic model for this cluster\n",
    "            topic_model, perplexity, coherence = topic_modeling(clustered_texts, clustered_corpus, dictionary, topic_modeling_algorithm, RANDOM_SEED)\n",
    "            \n",
    "            # Save the topic model\n",
    "            topic_models[label] = topic_model\n",
    "            \n",
    "            # Save the scores\n",
    "            coherence_scores[label] = coherence\n",
    "            if perplexity is not None: perplexity_scores[label] = perplexity\n",
    "\n",
    "        coherence = np.mean(list(coherence_scores.values()))\n",
    "        if len(perplexity_scores) == 0: perplexity = None\n",
    "        else: perplexity = np.mean(list(perplexity_scores.values()))\n",
    "    \n",
    "    else:\n",
    "        print('Topic modeling without clustering...')\n",
    "        topic_model, perplexity, coherence = topic_modeling(procd_data_bigram, corpus, dictionary, topic_modeling_algorithm, num_topics, RANDOM_SEED)\n",
    "    \n",
    "    return num_docs, clustering_model if clustering else None, silhouette if clustering else None, calinski_harabasz if clustering else None, davies_bouldin if clustering else None, topic_models if clustering else topic_model, coherence, perplexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Set up path and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "train_data_path = '../data/raw/lewtun-drug-reviews/train.jsonl'\n",
    "\n",
    "# Feature Engineering\n",
    "procd_texts = ['lemma_wo_stpwrd', 'lemma_w_stpwrd']\n",
    "ngram = 'bigram'\n",
    "feature = 'tfidf'\n",
    "#bert_pretrained_model = 'bert-base-uncased'\n",
    "\n",
    "# Clustering\n",
    "clustering = False\n",
    "#clustering_algorithms = ['kmeans', 'hierarchical']\n",
    "#num_clusters = 2\n",
    "\n",
    "# Topic Modeling\n",
    "topic_modeling_algorithm = 'lda'\n",
    "nums_topics = [6, 10, 14, 16, 18]\n",
    "\n",
    "# Model Settings\n",
    "models = [\n",
    "    {'procd_text': 'lemma_w_stpwrd', 'num_topics': 18},\n",
    "    {'procd_text': 'lemma_w_stpwrd', 'num_topics': 16},\n",
    "    {'procd_text': 'lemma_w_stpwrd', 'num_topics': 14},\n",
    "    {'procd_text': 'lemma_w_stpwrd', 'num_topics': 10},\n",
    "    {'procd_text': 'lemma_w_stpwrd', 'num_topics': 6},\n",
    "    {'procd_text': 'lemma_wo_stpwrd', 'num_topics': 16}\n",
    "    #{'procd_text': 'lemma_w_stpwrd', 'clustering': True, 'clustering_algorithms': 'kmeans', 'num_clusters': 2, 'topic_modeling_algorithm': 'lda', 'num_topics': 8},\n",
    "    #{'procd_text': 'lemma_wo_stpwrd', 'clustering': True, 'clustering_algorithms': 'hierarchical', 'num_clusters': 3, 'topic_modeling_algorithm': 'lda', 'num_topics': 12}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Preprocess train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "procd_df_path = '../cross_validation/procd_train.csv'\n",
    "\n",
    "if os.path.isfile(procd_df_path): procd_df = pd.read_csv(procd_df_path)\n",
    "else:\n",
    "    procd_df = preprocess(Path(train_data_path), pct=1, RANDOM_SEED=RANDOM_SEED)\n",
    "    procd_df.to_csv(procd_df_path, index=False)\n",
    "    procd_df = pd.read_csv(procd_df_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folds:: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Preprocessed Text::   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemma_wo_stpwrd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/129036 [00:00<?, ?it/s]\n",
      "\n",
      "  1%|          | 1510/129036 [00:00<00:08, 14982.17it/s]\n",
      "\n",
      "  2%|▏         | 3127/129036 [00:00<00:08, 15631.93it/s]\n",
      "\n",
      "  4%|▍         | 5008/129036 [00:00<00:07, 17038.39it/s]\n",
      "\n",
      "  5%|▌         | 6756/129036 [00:00<00:07, 17177.49it/s]\n",
      "\n",
      "  7%|▋         | 8717/129036 [00:00<00:06, 18018.27it/s]\n",
      "\n",
      "  8%|▊         | 10808/129036 [00:00<00:06, 18982.80it/s]\n",
      "\n",
      " 10%|▉         | 12723/129036 [00:00<00:06, 19002.08it/s]\n",
      "\n",
      " 12%|█▏        | 15020/129036 [00:00<00:05, 20236.03it/s]\n",
      "\n",
      " 13%|█▎        | 17044/129036 [00:01<00:18, 6097.88it/s] \n",
      "\n",
      " 15%|█▌        | 19399/129036 [00:01<00:13, 8155.28it/s]\n",
      "\n",
      " 17%|█▋        | 21818/129036 [00:01<00:10, 10461.94it/s]\n",
      "\n",
      " 19%|█▊        | 24155/129036 [00:01<00:08, 12647.57it/s]\n",
      "\n",
      " 21%|██        | 26567/129036 [00:02<00:06, 14891.52it/s]\n",
      "\n",
      " 22%|██▏       | 28831/129036 [00:02<00:06, 16572.88it/s]\n",
      "\n",
      " 24%|██▍       | 31021/129036 [00:02<00:05, 17837.32it/s]\n",
      "\n",
      " 26%|██▌       | 33211/129036 [00:02<00:05, 18578.47it/s]\n",
      "\n",
      " 27%|██▋       | 35435/129036 [00:02<00:04, 19525.58it/s]\n",
      "\n",
      " 29%|██▉       | 37645/129036 [00:02<00:04, 20194.47it/s]\n",
      "\n",
      " 31%|███       | 39824/129036 [00:02<00:04, 20560.89it/s]\n",
      "\n",
      " 33%|███▎      | 42104/129036 [00:02<00:04, 21182.89it/s]\n",
      "\n",
      " 34%|███▍      | 44485/129036 [00:02<00:03, 21910.03it/s]\n",
      "\n",
      " 36%|███▋      | 46786/129036 [00:02<00:03, 22094.03it/s]\n",
      "\n",
      " 38%|███▊      | 49066/129036 [00:03<00:03, 22238.71it/s]\n",
      "\n",
      " 40%|███▉      | 51402/129036 [00:03<00:03, 22567.04it/s]\n",
      "\n",
      " 42%|████▏     | 53756/129036 [00:03<00:03, 22816.66it/s]\n",
      "\n",
      " 43%|████▎     | 56071/129036 [00:03<00:03, 22901.54it/s]\n",
      "\n",
      " 45%|████▌     | 58372/129036 [00:03<00:03, 22772.29it/s]\n",
      "\n",
      " 47%|████▋     | 60715/129036 [00:03<00:02, 22916.92it/s]\n",
      "\n",
      " 49%|████▉     | 63013/129036 [00:03<00:02, 22837.66it/s]\n",
      "\n",
      " 51%|█████     | 65308/129036 [00:03<00:02, 22867.24it/s]\n",
      "\n",
      " 53%|█████▎    | 67764/129036 [00:03<00:02, 23352.35it/s]\n",
      "\n",
      " 54%|█████▍    | 70163/129036 [00:03<00:02, 23482.26it/s]\n",
      "\n",
      " 56%|█████▌    | 72513/129036 [00:04<00:02, 23281.54it/s]\n",
      "\n",
      " 58%|█████▊    | 74895/129036 [00:04<00:02, 23371.80it/s]\n",
      "\n",
      " 60%|█████▉    | 77255/129036 [00:04<00:02, 23409.72it/s]\n",
      "\n",
      " 62%|██████▏   | 79597/129036 [00:04<00:02, 23334.03it/s]\n",
      "\n",
      " 64%|██████▎   | 81948/129036 [00:04<00:02, 23374.26it/s]\n",
      "\n",
      " 65%|██████▌   | 84335/129036 [00:04<00:01, 23487.14it/s]\n",
      "\n",
      " 67%|██████▋   | 86723/129036 [00:04<00:01, 23590.61it/s]\n",
      "\n",
      " 69%|██████▉   | 89083/129036 [00:04<00:01, 23336.58it/s]\n",
      "\n",
      " 71%|███████   | 91488/129036 [00:04<00:01, 23547.03it/s]\n",
      "\n",
      " 73%|███████▎  | 93904/129036 [00:04<00:01, 23719.26it/s]\n",
      "\n",
      " 75%|███████▍  | 96277/129036 [00:05<00:01, 23427.64it/s]\n",
      "\n",
      " 76%|███████▋  | 98621/129036 [00:05<00:01, 23270.19it/s]\n",
      "\n",
      " 78%|███████▊  | 100968/129036 [00:05<00:01, 23265.55it/s]\n",
      "\n",
      " 80%|████████  | 103298/129036 [00:05<00:01, 23263.62it/s]\n",
      "\n",
      " 82%|████████▏ | 105625/129036 [00:05<00:01, 23239.98it/s]\n",
      "\n",
      " 84%|████████▎ | 107950/129036 [00:05<00:00, 23151.61it/s]\n",
      "\n",
      " 85%|████████▌ | 110292/129036 [00:05<00:00, 23191.61it/s]\n",
      "\n",
      " 87%|████████▋ | 112650/129036 [00:05<00:00, 23298.78it/s]\n",
      "\n",
      " 89%|████████▉ | 114981/129036 [00:05<00:00, 22803.67it/s]\n",
      "\n",
      " 91%|█████████ | 117264/129036 [00:06<00:00, 22663.52it/s]\n",
      "\n",
      " 93%|█████████▎| 119532/129036 [00:06<00:00, 21737.51it/s]\n",
      "\n",
      " 94%|█████████▍| 121714/129036 [00:06<00:00, 21355.68it/s]\n",
      "\n",
      " 96%|█████████▌| 123941/129036 [00:06<00:00, 21618.40it/s]\n",
      "\n",
      " 98%|█████████▊| 126140/129036 [00:06<00:00, 21723.86it/s]\n",
      "\n",
      "100%|██████████| 129036/129036 [00:06<00:00, 19691.08it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 129036/129036 [00:00<00:00, 1990768.18it/s]\n",
      "\n",
      "\n",
      "  0%|          | 0/32259 [00:00<?, ?it/s]\n",
      "\n",
      "  6%|▌         | 1967/32259 [00:00<00:01, 19593.41it/s]\n",
      "\n",
      " 12%|█▏        | 3944/32259 [00:00<00:01, 19593.92it/s]\n",
      "\n",
      " 19%|█▉        | 6230/32259 [00:00<00:01, 21032.14it/s]\n",
      "\n",
      " 27%|██▋       | 8640/32259 [00:00<00:01, 22204.10it/s]\n",
      "\n",
      " 34%|███▎      | 10861/32259 [00:00<00:00, 22202.02it/s]\n",
      "\n",
      " 41%|████      | 13213/32259 [00:00<00:00, 22630.23it/s]\n",
      "\n",
      " 48%|████▊     | 15572/32259 [00:00<00:00, 22874.08it/s]\n",
      "\n",
      " 55%|█████▌    | 17860/32259 [00:00<00:00, 22649.62it/s]\n",
      "\n",
      " 63%|██████▎   | 20238/32259 [00:00<00:00, 22974.41it/s]\n",
      "\n",
      " 70%|███████   | 22589/32259 [00:01<00:00, 23077.41it/s]\n",
      "\n",
      " 77%|███████▋  | 24901/32259 [00:01<00:00, 22971.98it/s]\n",
      "\n",
      " 84%|████████▍ | 27199/32259 [00:01<00:00, 22844.06it/s]\n",
      "\n",
      " 92%|█████████▏| 29533/32259 [00:01<00:00, 22933.72it/s]\n",
      "\n",
      "100%|██████████| 32259/32259 [00:01<00:00, 22613.42it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 32259/32259 [00:00<00:00, 2009595.46it/s]\n",
      "\n",
      "\n",
      "  0%|          | 0/129036 [00:00<?, ?it/s]\n",
      "\n",
      "  2%|▏         | 3205/129036 [00:00<00:03, 32030.25it/s]\n",
      "\n",
      "  5%|▌         | 6462/129036 [00:00<00:03, 32244.79it/s]\n",
      "\n",
      "  8%|▊         | 9687/129036 [00:00<00:03, 31771.51it/s]\n",
      "\n",
      " 10%|▉         | 12865/129036 [00:00<00:03, 31496.22it/s]\n",
      "\n",
      " 12%|█▏        | 16016/129036 [00:00<00:03, 31154.66it/s]\n",
      "\n",
      " 15%|█▍        | 19133/129036 [00:00<00:03, 30199.56it/s]\n",
      "\n",
      " 17%|█▋        | 22158/129036 [00:00<00:03, 30171.23it/s]\n",
      "\n",
      " 20%|█▉        | 25179/129036 [00:00<00:03, 29673.57it/s]\n",
      "\n",
      " 22%|██▏       | 28150/129036 [00:00<00:03, 29186.17it/s]\n",
      "\n",
      " 24%|██▍       | 31071/129036 [00:01<00:03, 28775.46it/s]\n",
      "\n",
      " 26%|██▋       | 33951/129036 [00:01<00:03, 28072.57it/s]\n",
      "\n",
      " 28%|██▊       | 36762/129036 [00:01<00:03, 27385.48it/s]\n",
      "\n",
      " 31%|███       | 39617/129036 [00:01<00:03, 27708.16it/s]\n",
      "\n",
      " 33%|███▎      | 42470/129036 [00:01<00:03, 27918.29it/s]\n",
      "\n",
      " 35%|███▌      | 45266/129036 [00:01<00:03, 27378.28it/s]\n",
      "\n",
      " 37%|███▋      | 48040/129036 [00:01<00:02, 27409.67it/s]\n",
      "\n",
      " 39%|███▉      | 50784/129036 [00:01<00:02, 27298.43it/s]\n",
      "\n",
      " 41%|████▏     | 53516/129036 [00:01<00:02, 27041.05it/s]\n",
      "\n",
      " 44%|████▎     | 56222/129036 [00:01<00:02, 27001.81it/s]\n",
      "\n",
      " 46%|████▌     | 58996/129036 [00:02<00:02, 27215.17it/s]\n",
      "\n",
      " 48%|████▊     | 61719/129036 [00:02<00:02, 26684.63it/s]\n",
      "\n",
      " 50%|████▉     | 64395/129036 [00:02<00:02, 26636.44it/s]\n",
      "\n",
      " 52%|█████▏    | 67061/129036 [00:02<00:02, 26252.62it/s]\n",
      "\n",
      " 54%|█████▍    | 69689/129036 [00:02<00:02, 25760.05it/s]\n",
      "\n",
      " 56%|█████▌    | 72449/129036 [00:02<00:02, 26224.10it/s]\n",
      "\n",
      " 58%|█████▊    | 75233/129036 [00:02<00:02, 26662.45it/s]\n",
      "\n",
      " 60%|██████    | 77902/129036 [00:02<00:01, 26058.43it/s]\n",
      "\n",
      " 62%|██████▏   | 80574/129036 [00:02<00:01, 26202.69it/s]\n",
      "\n",
      " 65%|██████▍   | 83274/129036 [00:02<00:01, 26391.25it/s]\n",
      "\n",
      " 67%|██████▋   | 85916/129036 [00:03<00:05, 8264.93it/s] \n",
      "\n",
      " 69%|██████▊   | 88490/129036 [00:03<00:03, 10298.43it/s]\n",
      "\n",
      " 71%|███████   | 91154/129036 [00:04<00:03, 12618.57it/s]\n",
      "\n",
      " 73%|███████▎  | 93728/129036 [00:04<00:02, 14830.11it/s]\n",
      "\n",
      " 75%|███████▍  | 96357/129036 [00:04<00:01, 17059.35it/s]\n",
      "\n",
      " 77%|███████▋  | 99043/129036 [00:04<00:01, 19170.07it/s]\n",
      "\n",
      " 79%|███████▉  | 101685/129036 [00:04<00:01, 20885.91it/s]\n",
      "\n",
      " 81%|████████  | 104238/129036 [00:04<00:01, 22037.16it/s]\n",
      "\n",
      " 83%|████████▎ | 106846/129036 [00:04<00:00, 23097.27it/s]\n",
      "\n",
      " 85%|████████▍ | 109444/129036 [00:04<00:00, 23861.88it/s]\n",
      "\n",
      " 87%|████████▋ | 112016/129036 [00:04<00:00, 24132.08it/s]\n",
      "\n",
      " 89%|████████▉ | 114561/129036 [00:04<00:00, 24437.44it/s]\n",
      "\n",
      " 91%|█████████ | 117195/129036 [00:05<00:00, 24949.75it/s]\n",
      "\n",
      " 93%|█████████▎| 119758/129036 [00:05<00:00, 24846.39it/s]\n",
      "\n",
      " 95%|█████████▍| 122290/129036 [00:05<00:00, 24708.72it/s]\n",
      "\n",
      " 97%|█████████▋| 124883/129036 [00:05<00:00, 25020.68it/s]\n",
      "\n",
      "100%|██████████| 129036/129036 [00:05<00:00, 23353.52it/s]\n",
      "\n",
      "\n",
      "Generating BoW:   0%|          | 0/129036 [00:00<?, ?it/s]\n",
      "\n",
      "Generating BoW:   5%|▍         | 6377/129036 [00:00<00:01, 63261.92it/s]\n",
      "\n",
      "Generating BoW:  10%|▉         | 12827/129036 [00:00<00:01, 63682.77it/s]\n",
      "\n",
      "Generating BoW:  15%|█▍        | 19196/129036 [00:00<00:01, 63403.98it/s]\n",
      "\n",
      "Generating BoW:  20%|█▉        | 25705/129036 [00:00<00:01, 63920.11it/s]\n",
      "\n",
      "Generating BoW:  25%|██▌       | 32350/129036 [00:00<00:01, 64697.40it/s]\n",
      "\n",
      "Generating BoW:  30%|███       | 38959/129036 [00:00<00:01, 64954.33it/s]\n",
      "\n",
      "Generating BoW:  35%|███▌      | 45455/129036 [00:00<00:01, 64725.25it/s]\n",
      "\n",
      "Generating BoW:  40%|████      | 51928/129036 [00:00<00:01, 64231.04it/s]\n",
      "\n",
      "Generating BoW:  45%|████▌     | 58352/129036 [00:00<00:01, 63987.04it/s]\n",
      "\n",
      "Generating BoW:  50%|█████     | 64752/129036 [00:01<00:01, 63538.07it/s]\n",
      "\n",
      "Generating BoW:  55%|█████▌    | 71123/129036 [00:01<00:00, 63499.13it/s]\n",
      "\n",
      "Generating BoW:  60%|██████    | 77557/129036 [00:01<00:00, 63738.62it/s]\n",
      "\n",
      "Generating BoW:  65%|██████▌   | 83932/129036 [00:01<00:00, 63512.61it/s]\n",
      "\n",
      "Generating BoW:  70%|██████▉   | 90284/129036 [00:01<00:00, 63164.63it/s]\n",
      "\n",
      "Generating BoW:  75%|███████▍  | 96601/129036 [00:01<00:00, 62331.87it/s]\n",
      "\n",
      "Generating BoW:  80%|███████▉  | 102837/129036 [00:01<00:00, 61440.40it/s]\n",
      "\n",
      "Generating BoW:  84%|████████▍ | 108985/129036 [00:01<00:00, 60968.50it/s]\n",
      "\n",
      "Generating BoW:  90%|████████▉ | 115523/129036 [00:01<00:00, 62152.23it/s]\n",
      "\n",
      "Generating BoW: 100%|██████████| 129036/129036 [00:02<00:00, 63738.64it/s]\n",
      "\n",
      "\n",
      "Generating TF-IDF:   0%|          | 0/129036 [00:00<?, ?it/s]\n",
      "\n",
      "Generating TF-IDF:   3%|▎         | 3834/129036 [00:00<00:03, 38309.62it/s]\n",
      "\n",
      "Generating TF-IDF:   6%|▌         | 7757/129036 [00:00<00:03, 38538.78it/s]\n",
      "\n",
      "Generating TF-IDF:   9%|▉         | 11611/129036 [00:00<00:03, 38419.44it/s]\n",
      "\n",
      "Generating TF-IDF:  12%|█▏        | 15519/129036 [00:00<00:02, 38609.10it/s]\n",
      "\n",
      "Generating TF-IDF:  15%|█▌        | 19380/129036 [00:00<00:02, 37650.47it/s]\n",
      "\n",
      "Generating TF-IDF:  18%|█▊        | 23244/129036 [00:00<00:02, 37888.00it/s]\n",
      "\n",
      "Generating TF-IDF:  21%|██        | 27103/129036 [00:00<00:02, 38008.77it/s]\n",
      "\n",
      "Generating TF-IDF:  24%|██▍       | 30906/129036 [00:00<00:02, 37890.77it/s]\n",
      "\n",
      "Generating TF-IDF:  27%|██▋       | 34697/129036 [00:00<00:02, 36969.70it/s]\n",
      "\n",
      "Generating TF-IDF:  30%|██▉       | 38399/129036 [00:01<00:02, 34440.87it/s]\n",
      "\n",
      "Generating TF-IDF:  32%|███▏      | 41876/129036 [00:01<00:02, 33463.04it/s]\n",
      "\n",
      "Generating TF-IDF:  35%|███▌      | 45246/129036 [00:01<00:02, 33304.03it/s]\n",
      "\n",
      "Generating TF-IDF:  38%|███▊      | 48592/129036 [00:01<00:02, 32710.94it/s]\n",
      "\n",
      "Generating TF-IDF:  40%|████      | 51874/129036 [00:01<00:02, 32206.60it/s]\n",
      "\n",
      "Generating TF-IDF:  43%|████▎     | 55102/129036 [00:01<00:02, 32189.56it/s]\n",
      "\n",
      "Generating TF-IDF:  45%|████▌     | 58326/129036 [00:01<00:02, 32124.12it/s]\n",
      "\n",
      "Generating TF-IDF:  48%|████▊     | 61862/129036 [00:01<00:02, 32989.82it/s]\n",
      "\n",
      "Generating TF-IDF:  51%|█████     | 65718/129036 [00:01<00:01, 34549.37it/s]\n",
      "\n",
      "Generating TF-IDF:  54%|█████▍    | 69538/129036 [00:01<00:01, 35529.63it/s]\n",
      "\n",
      "Generating TF-IDF:  57%|█████▋    | 73444/129036 [00:02<00:01, 36489.79it/s]\n",
      "\n",
      "Generating TF-IDF:  60%|█████▉    | 77180/129036 [00:02<00:01, 36706.42it/s]\n",
      "\n",
      "Generating TF-IDF:  63%|██████▎   | 80974/129036 [00:02<00:01, 36968.19it/s]\n",
      "\n",
      "Generating TF-IDF:  66%|██████▌   | 84738/129036 [00:02<00:01, 37135.88it/s]\n",
      "\n",
      "Generating TF-IDF:  69%|██████▊   | 88508/129036 [00:02<00:01, 37298.40it/s]\n",
      "\n",
      "Generating TF-IDF:  72%|███████▏  | 92307/129036 [00:02<00:00, 37462.85it/s]\n",
      "\n",
      "Generating TF-IDF:  75%|███████▍  | 96158/129036 [00:02<00:00, 37715.03it/s]\n",
      "\n",
      "Generating TF-IDF:  77%|███████▋  | 99931/129036 [00:02<00:00, 36937.00it/s]\n",
      "\n",
      "Generating TF-IDF:  80%|████████  | 103719/129036 [00:02<00:00, 37135.84it/s]\n",
      "\n",
      "Generating TF-IDF:  83%|████████▎ | 107436/129036 [00:04<00:02, 9091.51it/s] \n",
      "\n",
      "Generating TF-IDF:  86%|████████▌ | 111181/129036 [00:04<00:01, 11743.37it/s]\n",
      "\n",
      "Generating TF-IDF:  89%|████████▉ | 115170/129036 [00:04<00:00, 15052.14it/s]\n",
      "\n",
      "Generating TF-IDF:  92%|█████████▏| 119117/129036 [00:04<00:00, 18558.92it/s]\n",
      "\n",
      "Generating TF-IDF:  95%|█████████▌| 122986/129036 [00:04<00:00, 21965.81it/s]\n",
      "\n",
      "Generating TF-IDF: 100%|██████████| 129036/129036 [00:04<00:00, 28126.34it/s]\n",
      "\n",
      "\n",
      "Training topic models::   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 topics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training topic models::  60%|██████    | 3/5 [01:27<00:58, 29.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 topics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training topic models::  80%|████████  | 4/5 [03:03<00:50, 50.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 topics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training topic models:: 100%|██████████| 5/5 [04:43<00:00, 56.71s/it]\n",
      "\n",
      "Preprocessed Text::  50%|█████     | 1/2 [05:11<05:11, 311.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemma_w_stpwrd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/129036 [00:00<?, ?it/s]\n",
      "\n",
      "  1%|          | 922/129036 [00:00<00:13, 9201.21it/s]\n",
      "\n",
      "  1%|▏         | 1891/129036 [00:00<00:13, 9445.56it/s]\n",
      "\n",
      "  2%|▏         | 2900/129036 [00:00<00:12, 9704.29it/s]\n",
      "\n",
      "  3%|▎         | 3971/129036 [00:00<00:12, 10083.76it/s]\n",
      "\n",
      "  4%|▍         | 5001/129036 [00:00<00:12, 10161.14it/s]\n",
      "\n",
      "  5%|▍         | 6021/129036 [00:00<00:12, 10161.27it/s]\n",
      "\n",
      "  5%|▌         | 7038/129036 [00:00<00:12, 10161.29it/s]\n",
      "\n",
      "  6%|▋         | 8101/129036 [00:00<00:11, 10296.15it/s]\n",
      "\n",
      "  7%|▋         | 9169/129036 [00:00<00:11, 10411.08it/s]\n",
      "\n",
      "  8%|▊         | 10307/129036 [00:01<00:11, 10645.42it/s]\n",
      "\n",
      "  9%|▉         | 11383/129036 [00:01<00:11, 10657.31it/s]\n",
      "\n",
      " 10%|▉         | 12449/129036 [00:01<00:11, 10540.67it/s]\n",
      "\n",
      " 10%|█         | 13504/129036 [00:01<00:11, 10362.70it/s]\n",
      "\n",
      " 11%|█▏        | 14558/129036 [00:01<00:11, 10389.99it/s]\n",
      "\n",
      " 12%|█▏        | 15598/129036 [00:01<00:10, 10319.41it/s]\n",
      "\n",
      " 13%|█▎        | 16637/129036 [00:01<00:10, 10324.40it/s]\n",
      "\n",
      " 14%|█▎        | 17674/129036 [00:01<00:10, 10328.34it/s]\n",
      "\n",
      " 14%|█▍        | 18707/129036 [00:01<00:10, 10319.77it/s]\n",
      "\n",
      " 15%|█▌        | 19765/129036 [00:01<00:10, 10366.94it/s]\n",
      "\n",
      " 16%|█▌        | 20816/129036 [00:02<00:10, 10395.30it/s]\n",
      "\n",
      " 17%|█▋        | 21856/129036 [00:02<00:10, 10022.41it/s]\n",
      "\n",
      " 18%|█▊        | 22925/129036 [00:02<00:10, 10203.71it/s]\n",
      "\n",
      " 19%|█▊        | 23948/129036 [00:02<00:10, 10107.29it/s]\n",
      "\n",
      " 19%|█▉        | 24989/129036 [00:02<00:10, 10195.88it/s]\n",
      "\n",
      " 20%|██        | 26037/129036 [00:02<00:10, 10265.04it/s]\n",
      "\n",
      " 21%|██        | 27104/129036 [00:02<00:09, 10370.05it/s]\n",
      "\n",
      " 22%|██▏       | 28142/129036 [00:02<00:10, 10036.21it/s]\n",
      "\n",
      " 23%|██▎       | 29193/129036 [00:02<00:09, 10152.70it/s]\n",
      "\n",
      " 23%|██▎       | 30211/129036 [00:02<00:09, 9889.71it/s] \n",
      "\n",
      " 24%|██▍       | 31264/129036 [00:03<00:09, 10047.60it/s]\n",
      "\n",
      " 25%|██▌       | 32316/129036 [00:03<00:09, 10169.06it/s]\n",
      "\n",
      " 26%|██▌       | 33335/129036 [00:03<00:09, 10171.33it/s]\n",
      "\n",
      " 27%|██▋       | 34354/129036 [00:03<00:09, 10166.72it/s]\n",
      "\n",
      " 27%|██▋       | 35406/129036 [00:03<00:09, 10255.88it/s]\n",
      "\n",
      " 28%|██▊       | 36433/129036 [00:03<00:09, 10222.33it/s]\n",
      "\n",
      " 29%|██▉       | 37456/129036 [00:03<00:09, 9990.38it/s] \n",
      "\n",
      " 30%|██▉       | 38457/129036 [00:03<00:09, 9865.34it/s]\n",
      "\n",
      " 31%|███       | 39461/129036 [00:03<00:09, 9893.06it/s]\n",
      "\n",
      " 31%|███▏      | 40452/129036 [00:03<00:08, 9884.36it/s]\n",
      "\n",
      " 32%|███▏      | 41468/129036 [00:04<00:08, 9937.06it/s]\n",
      "\n",
      " 33%|███▎      | 42463/129036 [00:04<00:08, 9704.75it/s]\n",
      "\n",
      " 34%|███▎      | 43523/129036 [00:04<00:08, 9941.48it/s]\n",
      "\n",
      " 35%|███▍      | 44556/129036 [00:04<00:08, 10035.87it/s]\n",
      "\n",
      " 35%|███▌      | 45639/129036 [00:04<00:08, 10252.81it/s]\n",
      "\n",
      " 36%|███▌      | 46666/129036 [00:04<00:08, 10193.79it/s]\n",
      "\n",
      " 37%|███▋      | 47744/129036 [00:04<00:07, 10344.04it/s]\n",
      "\n",
      " 38%|███▊      | 48821/129036 [00:04<00:07, 10449.24it/s]\n",
      "\n",
      " 39%|███▊      | 49915/129036 [00:04<00:07, 10565.53it/s]\n",
      "\n",
      " 40%|███▉      | 51057/129036 [00:04<00:07, 10793.16it/s]\n",
      "\n",
      " 40%|████      | 52137/129036 [00:05<00:07, 10782.71it/s]\n",
      "\n",
      " 41%|████      | 53216/129036 [00:05<00:07, 10766.05it/s]\n",
      "\n",
      " 42%|████▏     | 54310/129036 [00:05<00:06, 10795.80it/s]\n",
      "\n",
      " 43%|████▎     | 55390/129036 [00:05<00:07, 10439.62it/s]\n",
      "\n",
      " 44%|████▍     | 56506/129036 [00:05<00:06, 10639.25it/s]\n",
      "\n",
      " 45%|████▍     | 57613/129036 [00:05<00:06, 10751.77it/s]\n",
      "\n",
      " 46%|████▌     | 58751/129036 [00:05<00:06, 10929.46it/s]\n",
      "\n",
      " 46%|████▋     | 59852/129036 [00:05<00:06, 10939.35it/s]\n",
      "\n",
      " 47%|████▋     | 60947/129036 [00:05<00:06, 10877.55it/s]\n",
      "\n",
      " 48%|████▊     | 62036/129036 [00:06<00:06, 10781.68it/s]\n",
      "\n",
      " 49%|████▉     | 63115/129036 [00:06<00:06, 10501.22it/s]\n",
      "\n",
      " 50%|████▉     | 64195/129036 [00:06<00:06, 10583.92it/s]\n",
      "\n",
      " 51%|█████     | 65255/129036 [00:06<00:06, 10565.17it/s]\n",
      "\n",
      " 51%|█████▏    | 66331/129036 [00:06<00:05, 10611.66it/s]\n",
      "\n",
      " 52%|█████▏    | 67393/129036 [00:06<00:05, 10595.56it/s]\n",
      "\n",
      " 53%|█████▎    | 68465/129036 [00:06<00:05, 10611.09it/s]\n",
      "\n",
      " 54%|█████▍    | 69527/129036 [00:06<00:05, 10532.42it/s]\n",
      "\n",
      " 55%|█████▍    | 70617/129036 [00:06<00:05, 10615.02it/s]\n",
      "\n",
      " 56%|█████▌    | 71679/129036 [00:06<00:05, 10257.76it/s]\n",
      "\n",
      " 56%|█████▋    | 72725/129036 [00:07<00:05, 10289.69it/s]\n",
      "\n",
      " 57%|█████▋    | 73756/129036 [00:07<00:05, 9874.48it/s] \n",
      "\n",
      " 58%|█████▊    | 74755/129036 [00:07<00:05, 9900.27it/s]\n",
      "\n",
      " 59%|█████▊    | 75794/129036 [00:07<00:05, 10026.10it/s]\n",
      "\n",
      " 60%|█████▉    | 76800/129036 [00:07<00:05, 9996.51it/s] \n",
      "\n",
      " 60%|██████    | 77802/129036 [00:07<00:05, 9870.06it/s]\n",
      "\n",
      " 61%|██████    | 78791/129036 [00:07<00:05, 9835.09it/s]\n",
      "\n",
      " 62%|██████▏   | 79776/129036 [00:07<00:05, 9489.86it/s]\n",
      "\n",
      " 63%|██████▎   | 80729/129036 [00:07<00:05, 9497.85it/s]\n",
      "\n",
      " 63%|██████▎   | 81745/129036 [00:07<00:04, 9671.43it/s]\n",
      "\n",
      " 64%|██████▍   | 82800/129036 [00:08<00:04, 9921.47it/s]\n",
      "\n",
      " 65%|██████▍   | 83828/129036 [00:08<00:04, 10024.80it/s]\n",
      "\n",
      " 66%|██████▌   | 84923/129036 [00:08<00:04, 10288.35it/s]\n",
      "\n",
      " 67%|██████▋   | 86065/129036 [00:08<00:04, 10609.53it/s]\n",
      "\n",
      " 68%|██████▊   | 87172/129036 [00:08<00:03, 10715.31it/s]\n",
      "\n",
      " 68%|██████▊   | 88245/129036 [00:08<00:03, 10567.22it/s]\n",
      "\n",
      " 69%|██████▉   | 89305/129036 [00:08<00:03, 10565.98it/s]\n",
      "\n",
      " 70%|███████   | 90413/129036 [00:08<00:03, 10705.51it/s]\n",
      "\n",
      " 71%|███████   | 91512/129036 [00:08<00:03, 10786.57it/s]\n",
      "\n",
      " 72%|███████▏  | 92619/129036 [00:08<00:03, 10855.65it/s]\n",
      "\n",
      " 73%|███████▎  | 93716/129036 [00:09<00:03, 10863.29it/s]\n",
      "\n",
      " 73%|███████▎  | 94805/129036 [00:09<00:03, 10844.30it/s]\n",
      "\n",
      " 74%|███████▍  | 95893/129036 [00:09<00:03, 10830.72it/s]\n",
      "\n",
      " 75%|███████▌  | 96977/129036 [00:09<00:03, 10623.90it/s]\n",
      "\n",
      " 76%|███████▌  | 98070/129036 [00:09<00:02, 10690.17it/s]\n",
      "\n",
      " 77%|███████▋  | 99161/129036 [00:09<00:02, 10736.22it/s]\n",
      "\n",
      " 78%|███████▊  | 100260/129036 [00:09<00:02, 10782.22it/s]\n",
      "\n",
      " 79%|███████▊  | 101339/129036 [00:09<00:02, 10765.16it/s]\n",
      "\n",
      " 79%|███████▉  | 102416/129036 [00:09<00:02, 10685.27it/s]\n",
      "\n",
      " 80%|████████  | 103488/129036 [00:10<00:02, 10669.99it/s]\n",
      "\n",
      " 81%|████████  | 104556/129036 [00:10<00:02, 10529.70it/s]\n",
      "\n",
      " 82%|████████▏ | 105610/129036 [00:10<00:02, 10350.57it/s]\n",
      "\n",
      " 83%|████████▎ | 106653/129036 [00:10<00:02, 10369.32it/s]\n",
      "\n",
      " 83%|████████▎ | 107709/129036 [00:10<00:02, 10416.96it/s]\n",
      "\n",
      " 84%|████████▍ | 108767/129036 [00:10<00:01, 10445.11it/s]\n",
      "\n",
      " 85%|████████▌ | 109815/129036 [00:10<00:01, 10437.27it/s]\n",
      "\n",
      " 86%|████████▌ | 110872/129036 [00:10<00:01, 10471.79it/s]\n",
      "\n",
      " 87%|████████▋ | 111920/129036 [00:10<00:01, 10383.81it/s]\n",
      "\n",
      " 88%|████████▊ | 112959/129036 [00:10<00:01, 10071.04it/s]\n",
      "\n",
      " 88%|████████▊ | 113969/129036 [00:11<00:01, 10021.75it/s]\n",
      "\n",
      " 89%|████████▉ | 114973/129036 [00:11<00:01, 9987.09it/s] \n",
      "\n",
      " 90%|████████▉ | 116035/129036 [00:11<00:01, 10168.65it/s]\n",
      "\n",
      " 91%|█████████ | 117053/129036 [00:11<00:01, 10114.29it/s]\n",
      "\n",
      " 91%|█████████▏| 118066/129036 [00:11<00:01, 10118.07it/s]\n",
      "\n",
      " 92%|█████████▏| 119079/129036 [00:11<00:00, 10048.31it/s]\n",
      "\n",
      " 93%|█████████▎| 120085/129036 [00:11<00:00, 9935.48it/s] \n",
      "\n",
      " 94%|█████████▍| 121079/129036 [00:11<00:00, 9926.45it/s]\n",
      "\n",
      " 95%|█████████▍| 122072/129036 [00:11<00:00, 9854.28it/s]\n",
      "\n",
      " 95%|█████████▌| 123149/129036 [00:11<00:00, 10109.84it/s]\n",
      "\n",
      " 96%|█████████▋| 124284/129036 [00:12<00:00, 10448.67it/s]\n",
      "\n",
      " 97%|█████████▋| 125333/129036 [00:12<00:00, 10458.85it/s]\n",
      "\n",
      " 98%|█████████▊| 126383/129036 [00:12<00:00, 10461.19it/s]\n",
      "\n",
      " 99%|█████████▉| 127507/129036 [00:12<00:00, 10673.58it/s]\n",
      "\n",
      "100%|██████████| 129036/129036 [00:12<00:00, 10332.78it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 129036/129036 [00:00<00:00, 1877124.23it/s]\n",
      "\n",
      "\n",
      "  0%|          | 0/32259 [00:00<?, ?it/s]\n",
      "\n",
      "  3%|▎         | 985/32259 [00:00<00:03, 9759.70it/s]\n",
      "\n",
      "  6%|▋         | 2065/32259 [00:00<00:02, 10338.52it/s]\n",
      "\n",
      " 10%|▉         | 3124/32259 [00:00<00:02, 10451.30it/s]\n",
      "\n",
      " 13%|█▎        | 4219/32259 [00:00<00:02, 10612.59it/s]\n",
      "\n",
      " 16%|█▋        | 5303/32259 [00:00<00:02, 10673.05it/s]\n",
      "\n",
      " 20%|█▉        | 6371/32259 [00:00<00:02, 10622.91it/s]\n",
      "\n",
      " 23%|██▎       | 7444/32259 [00:00<00:02, 10638.92it/s]\n",
      "\n",
      " 26%|██▋       | 8525/32259 [00:00<00:02, 10691.04it/s]\n",
      "\n",
      " 30%|██▉       | 9595/32259 [00:00<00:02, 10310.87it/s]\n",
      "\n",
      " 33%|███▎      | 10629/32259 [00:01<00:02, 10274.64it/s]\n",
      "\n",
      " 36%|███▋      | 11715/32259 [00:01<00:01, 10437.98it/s]\n",
      "\n",
      " 40%|███▉      | 12798/32259 [00:01<00:01, 10536.86it/s]\n",
      "\n",
      " 43%|████▎     | 13864/32259 [00:01<00:01, 10568.87it/s]\n",
      "\n",
      " 46%|████▋     | 14931/32259 [00:01<00:01, 10570.33it/s]\n",
      "\n",
      " 50%|████▉     | 15989/32259 [00:01<00:01, 10437.86it/s]\n",
      "\n",
      " 53%|█████▎    | 17054/32259 [00:01<00:01, 10482.40it/s]\n",
      "\n",
      " 56%|█████▌    | 18103/32259 [00:01<00:01, 10216.63it/s]\n",
      "\n",
      " 59%|█████▉    | 19140/32259 [00:01<00:01, 10238.33it/s]\n",
      "\n",
      " 63%|██████▎   | 20202/32259 [00:01<00:01, 10342.46it/s]\n",
      "\n",
      " 66%|██████▌   | 21241/32259 [00:02<00:01, 10331.34it/s]\n",
      "\n",
      " 69%|██████▉   | 22275/32259 [00:02<00:00, 10312.02it/s]\n",
      "\n",
      " 72%|███████▏  | 23307/32259 [00:02<00:00, 10266.55it/s]\n",
      "\n",
      " 75%|███████▌  | 24334/32259 [00:02<00:00, 10128.64it/s]\n",
      "\n",
      " 79%|███████▊  | 25348/32259 [00:02<00:00, 9998.84it/s] \n",
      "\n",
      " 82%|████████▏ | 26349/32259 [00:02<00:00, 9713.39it/s]\n",
      "\n",
      " 85%|████████▍ | 27323/32259 [00:02<00:00, 9708.64it/s]\n",
      "\n",
      " 88%|████████▊ | 28299/32259 [00:02<00:00, 9711.65it/s]\n",
      "\n",
      " 91%|█████████ | 29316/32259 [00:02<00:00, 9832.77it/s]\n",
      "\n",
      " 94%|█████████▍| 30366/32259 [00:02<00:00, 10017.14it/s]\n",
      "\n",
      "100%|██████████| 32259/32259 [00:03<00:00, 10273.28it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 32259/32259 [00:00<00:00, 1865182.28it/s]\n",
      "\n",
      "\n",
      "  0%|          | 0/129036 [00:00<?, ?it/s]\n",
      "\n",
      "  1%|          | 1565/129036 [00:00<00:08, 15565.62it/s]\n",
      "\n",
      "  2%|▏         | 3122/129036 [00:00<00:08, 14428.05it/s]\n",
      "\n",
      "  4%|▎         | 4571/129036 [00:00<00:08, 14294.10it/s]\n",
      "\n",
      "  5%|▍         | 6003/129036 [00:00<00:08, 14029.85it/s]\n",
      "\n",
      "  6%|▌         | 7408/129036 [00:00<00:08, 13787.56it/s]\n",
      "\n",
      "  7%|▋         | 8788/129036 [00:00<00:08, 13755.76it/s]\n",
      "\n",
      "  8%|▊         | 10165/129036 [00:00<00:08, 13297.99it/s]\n",
      "\n",
      "  9%|▉         | 11498/129036 [00:00<00:09, 13054.78it/s]\n",
      "\n",
      " 10%|▉         | 12806/129036 [00:00<00:08, 13028.23it/s]\n",
      "\n",
      " 11%|█         | 14110/129036 [00:01<00:08, 12929.90it/s]\n",
      "\n",
      " 12%|█▏        | 15404/129036 [00:01<00:08, 12851.02it/s]\n",
      "\n",
      " 13%|█▎        | 16690/129036 [00:01<00:08, 12674.04it/s]\n",
      "\n",
      " 14%|█▍        | 17958/129036 [00:01<00:08, 12521.37it/s]\n",
      "\n",
      " 15%|█▍        | 19211/129036 [00:03<00:54, 2021.58it/s] \n",
      "\n",
      " 16%|█▌        | 20648/129036 [00:03<00:38, 2804.17it/s]\n",
      "\n",
      " 17%|█▋        | 21999/129036 [00:03<00:28, 3693.15it/s]\n",
      "\n",
      " 18%|█▊        | 23407/129036 [00:03<00:22, 4792.20it/s]\n",
      "\n",
      " 19%|█▉        | 24763/129036 [00:03<00:17, 5941.77it/s]\n",
      "\n",
      " 20%|██        | 26180/129036 [00:03<00:14, 7238.05it/s]\n",
      "\n",
      " 21%|██▏       | 27485/129036 [00:03<00:12, 8251.99it/s]\n",
      "\n",
      " 22%|██▏       | 28812/129036 [00:03<00:10, 9282.02it/s]\n",
      "\n",
      " 23%|██▎       | 30165/129036 [00:04<00:09, 10251.28it/s]\n",
      "\n",
      " 24%|██▍       | 31495/129036 [00:04<00:08, 10988.51it/s]\n",
      "\n",
      " 25%|██▌       | 32835/129036 [00:04<00:08, 11612.18it/s]\n",
      "\n",
      " 26%|██▋       | 34160/129036 [00:04<00:07, 11963.58it/s]\n",
      "\n",
      " 27%|██▋       | 35474/129036 [00:04<00:07, 12260.63it/s]\n",
      "\n",
      " 29%|██▊       | 36785/129036 [00:04<00:07, 12088.34it/s]\n",
      "\n",
      " 30%|██▉       | 38093/129036 [00:04<00:07, 12364.19it/s]\n",
      "\n",
      " 31%|███       | 39381/129036 [00:04<00:07, 12509.45it/s]\n",
      "\n",
      " 32%|███▏      | 40693/129036 [00:04<00:06, 12671.81it/s]\n",
      "\n",
      " 33%|███▎      | 41983/129036 [00:04<00:06, 12522.18it/s]\n",
      "\n",
      " 34%|███▎      | 43252/129036 [00:05<00:06, 12523.64it/s]\n",
      "\n",
      " 34%|███▍      | 44516/129036 [00:05<00:06, 12131.43it/s]\n",
      "\n",
      " 35%|███▌      | 45740/129036 [00:05<00:06, 12009.04it/s]\n",
      "\n",
      " 36%|███▋      | 46948/129036 [00:05<00:06, 11940.13it/s]\n",
      "\n",
      " 37%|███▋      | 48147/129036 [00:05<00:06, 11866.83it/s]\n",
      "\n",
      " 38%|███▊      | 49337/129036 [00:05<00:06, 11686.46it/s]\n",
      "\n",
      " 39%|███▉      | 50509/129036 [00:05<00:06, 11569.76it/s]\n",
      "\n",
      " 40%|████      | 51668/129036 [00:05<00:06, 11242.57it/s]\n",
      "\n",
      " 41%|████      | 52795/129036 [00:05<00:06, 10954.11it/s]\n",
      "\n",
      " 42%|████▏     | 53898/129036 [00:06<00:06, 10958.42it/s]\n",
      "\n",
      " 43%|████▎     | 54996/129036 [00:06<00:06, 10945.40it/s]\n",
      "\n",
      " 43%|████▎     | 56092/129036 [00:06<00:06, 10851.96it/s]\n",
      "\n",
      " 44%|████▍     | 57178/129036 [00:06<00:06, 10787.39it/s]\n",
      "\n",
      " 45%|████▌     | 58258/129036 [00:06<00:06, 10696.60it/s]\n",
      "\n",
      " 46%|████▌     | 59328/129036 [00:06<00:06, 10492.17it/s]\n",
      "\n",
      " 47%|████▋     | 60378/129036 [00:06<00:06, 10418.16it/s]\n",
      "\n",
      " 48%|████▊     | 61421/129036 [00:06<00:06, 10194.31it/s]\n",
      "\n",
      " 48%|████▊     | 62506/129036 [00:06<00:06, 10372.65it/s]\n",
      "\n",
      " 49%|████▉     | 63671/129036 [00:06<00:06, 10720.21it/s]\n",
      "\n",
      " 50%|█████     | 64803/129036 [00:07<00:05, 10891.13it/s]\n",
      "\n",
      " 51%|█████     | 65982/129036 [00:07<00:05, 11150.62it/s]\n",
      "\n",
      " 52%|█████▏    | 67290/129036 [00:07<00:05, 11698.25it/s]\n",
      "\n",
      " 53%|█████▎    | 68608/129036 [00:07<00:04, 12134.00it/s]\n",
      "\n",
      " 54%|█████▍    | 69848/129036 [00:07<00:04, 12184.46it/s]\n",
      "\n",
      " 55%|█████▌    | 71244/129036 [00:07<00:04, 12675.94it/s]\n",
      "\n",
      " 56%|█████▋    | 72588/129036 [00:07<00:04, 12877.09it/s]\n",
      "\n",
      " 57%|█████▋    | 73928/129036 [00:07<00:04, 13017.09it/s]\n",
      "\n",
      " 58%|█████▊    | 75271/129036 [00:07<00:04, 13104.79it/s]\n",
      "\n",
      " 59%|█████▉    | 76582/129036 [00:07<00:04, 13024.18it/s]\n",
      "\n",
      " 60%|██████    | 77885/129036 [00:08<00:04, 12686.32it/s]\n",
      "\n",
      " 61%|██████▏   | 79161/129036 [00:08<00:03, 12702.14it/s]\n",
      "\n",
      " 62%|██████▏   | 80433/129036 [00:08<00:03, 12698.59it/s]\n",
      "\n",
      " 63%|██████▎   | 81704/129036 [00:08<00:03, 12545.92it/s]\n",
      "\n",
      " 64%|██████▍   | 82960/129036 [00:08<00:03, 12547.56it/s]\n",
      "\n",
      " 65%|██████▌   | 84216/129036 [00:08<00:03, 12352.19it/s]\n",
      "\n",
      " 66%|██████▌   | 85453/129036 [00:08<00:03, 12257.46it/s]\n",
      "\n",
      " 67%|██████▋   | 86680/129036 [00:08<00:03, 12050.81it/s]\n",
      "\n",
      " 68%|██████▊   | 87886/129036 [00:08<00:03, 11991.29it/s]\n",
      "\n",
      " 69%|██████▉   | 89086/129036 [00:08<00:03, 11633.56it/s]\n",
      "\n",
      " 70%|██████▉   | 90252/129036 [00:09<00:03, 10687.70it/s]\n",
      "\n",
      " 71%|███████   | 91336/129036 [00:09<00:04, 9275.87it/s] \n",
      "\n",
      " 72%|███████▏  | 92302/129036 [00:09<00:04, 8695.76it/s]\n",
      "\n",
      " 72%|███████▏  | 93200/129036 [00:09<00:04, 8732.91it/s]\n",
      "\n",
      " 73%|███████▎  | 94105/129036 [00:09<00:03, 8796.34it/s]\n",
      "\n",
      " 74%|███████▍  | 95225/129036 [00:09<00:03, 9442.46it/s]\n",
      "\n",
      " 75%|███████▍  | 96337/129036 [00:09<00:03, 9890.34it/s]\n",
      "\n",
      " 75%|███████▌  | 97359/129036 [00:09<00:03, 9980.10it/s]\n",
      "\n",
      " 76%|███████▌  | 98389/129036 [00:10<00:03, 10062.80it/s]\n",
      "\n",
      " 77%|███████▋  | 99479/129036 [00:10<00:02, 10298.36it/s]\n",
      "\n",
      " 78%|███████▊  | 100572/129036 [00:10<00:02, 10472.03it/s]\n",
      "\n",
      " 79%|███████▉  | 101645/129036 [00:10<00:02, 10539.33it/s]\n",
      "\n",
      " 80%|███████▉  | 102717/129036 [00:10<00:02, 10580.77it/s]\n",
      "\n",
      " 80%|████████  | 103862/129036 [00:10<00:02, 10814.51it/s]\n",
      "\n",
      " 81%|████████▏ | 105068/129036 [00:10<00:02, 11156.87it/s]\n",
      "\n",
      " 82%|████████▏ | 106185/129036 [00:10<00:02, 11049.76it/s]\n",
      "\n",
      " 83%|████████▎ | 107292/129036 [00:10<00:01, 11051.02it/s]\n",
      "\n",
      " 84%|████████▍ | 108398/129036 [00:10<00:01, 10963.23it/s]\n",
      "\n",
      " 85%|████████▍ | 109559/129036 [00:11<00:01, 11139.53it/s]\n",
      "\n",
      " 86%|████████▌ | 110674/129036 [00:11<00:01, 11101.34it/s]\n",
      "\n",
      " 87%|████████▋ | 111785/129036 [00:11<00:01, 10921.85it/s]\n",
      "\n",
      " 88%|████████▊ | 113069/129036 [00:11<00:01, 11484.58it/s]\n",
      "\n",
      " 89%|████████▊ | 114347/129036 [00:11<00:01, 11836.79it/s]\n",
      "\n",
      " 90%|████████▉ | 115619/129036 [00:11<00:01, 12081.40it/s]\n",
      "\n",
      " 91%|█████████ | 116829/129036 [00:11<00:01, 11116.54it/s]\n",
      "\n",
      " 91%|█████████▏| 117957/129036 [00:11<00:01, 11054.10it/s]\n",
      "\n",
      " 92%|█████████▏| 119091/129036 [00:11<00:00, 11079.82it/s]\n",
      "\n",
      " 93%|█████████▎| 120248/129036 [00:11<00:00, 11189.27it/s]\n",
      "\n",
      " 94%|█████████▍| 121491/129036 [00:12<00:00, 11539.17it/s]\n",
      "\n",
      " 95%|█████████▌| 122782/129036 [00:12<00:00, 11938.90it/s]\n",
      "\n",
      " 96%|█████████▌| 124046/129036 [00:12<00:00, 12125.67it/s]\n",
      "\n",
      " 97%|█████████▋| 125290/129036 [00:12<00:00, 12194.45it/s]\n",
      "\n",
      " 98%|█████████▊| 126518/129036 [00:12<00:00, 12205.41it/s]\n",
      "\n",
      " 99%|█████████▉| 127741/129036 [00:12<00:00, 12042.47it/s]\n",
      "\n",
      "100%|██████████| 129036/129036 [00:12<00:00, 10182.23it/s]\n",
      "\n",
      "\n",
      "Generating BoW:   0%|          | 0/129036 [00:00<?, ?it/s]\n",
      "\n",
      "Generating BoW:   3%|▎         | 3752/129036 [00:00<00:03, 37514.67it/s]\n",
      "\n",
      "Generating BoW:   6%|▌         | 7606/129036 [00:00<00:03, 38102.67it/s]\n",
      "\n",
      "Generating BoW:   9%|▉         | 11549/129036 [00:00<00:03, 38695.48it/s]\n",
      "\n",
      "Generating BoW:  12%|█▏        | 15463/129036 [00:00<00:02, 38754.60it/s]\n",
      "\n",
      "Generating BoW:  15%|█▌        | 19405/129036 [00:00<00:02, 38900.14it/s]\n",
      "\n",
      "Generating BoW:  18%|█▊        | 23340/129036 [00:00<00:02, 38988.68it/s]\n",
      "\n",
      "Generating BoW:  21%|██        | 27239/129036 [00:00<00:02, 38867.11it/s]\n",
      "\n",
      "Generating BoW:  24%|██▍       | 31126/129036 [00:00<00:02, 38817.14it/s]\n",
      "\n",
      "Generating BoW:  27%|██▋       | 35012/129036 [00:00<00:02, 38801.86it/s]\n",
      "\n",
      "Generating BoW:  30%|███       | 38966/129036 [00:01<00:02, 39014.32it/s]\n",
      "\n",
      "Generating BoW:  33%|███▎      | 42868/129036 [00:01<00:02, 38731.35it/s]\n",
      "\n",
      "Generating BoW:  36%|███▋      | 46818/129036 [00:01<00:02, 38870.14it/s]\n",
      "\n",
      "Generating BoW:  39%|███▉      | 50706/129036 [00:01<00:02, 38620.74it/s]\n",
      "\n",
      "Generating BoW:  42%|████▏     | 54607/129036 [00:01<00:01, 38704.15it/s]\n",
      "\n",
      "Generating BoW:  45%|████▌     | 58478/129036 [00:01<00:01, 38668.19it/s]\n",
      "\n",
      "Generating BoW:  48%|████▊     | 62346/129036 [00:01<00:01, 38586.23it/s]\n",
      "\n",
      "Generating BoW:  51%|█████▏    | 66205/129036 [00:01<00:01, 38564.57it/s]\n",
      "\n",
      "Generating BoW:  54%|█████▍    | 70062/129036 [00:01<00:01, 38487.24it/s]\n",
      "\n",
      "Generating BoW:  57%|█████▋    | 73911/129036 [00:01<00:01, 37871.13it/s]\n",
      "\n",
      "Generating BoW:  60%|██████    | 77781/129036 [00:02<00:01, 38057.44it/s]\n",
      "\n",
      "Generating BoW:  63%|██████▎   | 81595/129036 [00:02<00:01, 38054.25it/s]\n",
      "\n",
      "Generating BoW:  66%|██████▌   | 85479/129036 [00:02<00:01, 38212.08it/s]\n",
      "\n",
      "Generating BoW:  69%|██████▉   | 89317/129036 [00:02<00:01, 38178.33it/s]\n",
      "\n",
      "Generating BoW:  72%|███████▏  | 93198/129036 [00:02<00:00, 38300.13it/s]\n",
      "\n",
      "Generating BoW:  75%|███████▌  | 97081/129036 [00:02<00:00, 38388.82it/s]\n",
      "\n",
      "Generating BoW:  78%|███████▊  | 100944/129036 [00:02<00:00, 38401.57it/s]\n",
      "\n",
      "Generating BoW:  81%|████████  | 104785/129036 [00:02<00:00, 38298.54it/s]\n",
      "\n",
      "Generating BoW:  84%|████████▍ | 108624/129036 [00:02<00:00, 38236.94it/s]\n",
      "\n",
      "Generating BoW:  87%|████████▋ | 112579/129036 [00:02<00:00, 38559.31it/s]\n",
      "\n",
      "Generating BoW:  90%|█████████ | 116472/129036 [00:03<00:00, 38655.92it/s]\n",
      "\n",
      "Generating BoW:  93%|█████████▎| 120338/129036 [00:03<00:00, 38589.15it/s]\n",
      "\n",
      "Generating BoW:  96%|█████████▋| 124295/129036 [00:03<00:00, 38797.88it/s]\n",
      "\n",
      "Generating BoW: 100%|██████████| 129036/129036 [00:03<00:00, 38552.13it/s]\n",
      "\n",
      "\n",
      "Generating TF-IDF:   0%|          | 0/129036 [00:00<?, ?it/s]\n",
      "\n",
      "Generating TF-IDF:   2%|▏         | 2241/129036 [00:00<00:05, 22349.75it/s]\n",
      "\n",
      "Generating TF-IDF:   4%|▎         | 4640/129036 [00:00<00:05, 23270.45it/s]\n",
      "\n",
      "Generating TF-IDF:   5%|▌         | 6968/129036 [00:00<00:05, 23123.39it/s]\n",
      "\n",
      "Generating TF-IDF:   7%|▋         | 9306/129036 [00:00<00:05, 23142.98it/s]\n",
      "\n",
      "Generating TF-IDF:   9%|▉         | 11686/129036 [00:00<00:05, 23295.55it/s]\n",
      "\n",
      "Generating TF-IDF:  11%|█         | 14016/129036 [00:00<00:04, 23259.37it/s]\n",
      "\n",
      "Generating TF-IDF:  13%|█▎        | 16342/129036 [00:00<00:04, 23078.80it/s]\n",
      "\n",
      "Generating TF-IDF:  15%|█▍        | 18745/129036 [00:00<00:04, 23316.69it/s]\n",
      "\n",
      "Generating TF-IDF:  16%|█▋        | 21107/129036 [00:00<00:04, 23397.52it/s]\n",
      "\n",
      "Generating TF-IDF:  18%|█▊        | 23447/129036 [00:01<00:04, 23278.59it/s]\n",
      "\n",
      "Generating TF-IDF:  20%|█▉        | 25776/129036 [00:01<00:04, 23247.20it/s]\n",
      "\n",
      "Generating TF-IDF:  22%|██▏       | 28105/129036 [00:01<00:04, 23241.18it/s]\n",
      "\n",
      "Generating TF-IDF:  24%|██▎       | 30430/129036 [00:01<00:04, 22923.90it/s]\n",
      "\n",
      "Generating TF-IDF:  25%|██▌       | 32724/129036 [00:01<00:04, 22842.46it/s]\n",
      "\n",
      "Generating TF-IDF:  27%|██▋       | 35009/129036 [00:01<00:04, 22730.79it/s]\n",
      "\n",
      "Generating TF-IDF:  29%|██▉       | 37302/129036 [00:01<00:04, 22771.87it/s]\n",
      "\n",
      "Generating TF-IDF:  31%|███       | 39615/129036 [00:01<00:03, 22857.40it/s]\n",
      "\n",
      "Generating TF-IDF:  33%|███▎      | 41938/129036 [00:01<00:03, 22951.17it/s]\n",
      "\n",
      "Generating TF-IDF:  34%|███▍      | 44277/129036 [00:01<00:03, 23051.60it/s]\n",
      "\n",
      "Generating TF-IDF:  36%|███▌      | 46583/129036 [00:02<00:03, 23051.92it/s]\n",
      "\n",
      "Generating TF-IDF:  38%|███▊      | 48901/129036 [00:02<00:03, 23049.14it/s]\n",
      "\n",
      "Generating TF-IDF:  40%|███▉      | 51248/129036 [00:02<00:03, 23168.59it/s]\n",
      "\n",
      "Generating TF-IDF:  42%|████▏     | 53619/129036 [00:02<00:03, 23269.43it/s]\n",
      "\n",
      "Generating TF-IDF:  43%|████▎     | 55946/129036 [00:02<00:03, 23198.21it/s]\n",
      "\n",
      "Generating TF-IDF:  45%|████▌     | 58300/129036 [00:02<00:03, 23261.88it/s]\n",
      "\n",
      "Generating TF-IDF:  47%|████▋     | 60634/129036 [00:02<00:02, 23254.33it/s]\n",
      "\n",
      "Generating TF-IDF:  49%|████▉     | 62962/129036 [00:02<00:02, 23195.35it/s]\n",
      "\n",
      "Generating TF-IDF:  51%|█████     | 65338/129036 [00:02<00:02, 23344.89it/s]\n",
      "\n",
      "Generating TF-IDF:  52%|█████▏    | 67716/129036 [00:02<00:02, 23422.89it/s]\n",
      "\n",
      "Generating TF-IDF:  54%|█████▍    | 70059/129036 [00:03<00:02, 23286.77it/s]\n",
      "\n",
      "Generating TF-IDF:  56%|█████▌    | 72388/129036 [00:03<00:02, 23213.89it/s]\n",
      "\n",
      "Generating TF-IDF:  58%|█████▊    | 74710/129036 [00:03<00:02, 23194.20it/s]\n",
      "\n",
      "Generating TF-IDF:  60%|█████▉    | 77030/129036 [00:03<00:02, 23106.51it/s]\n",
      "\n",
      "Generating TF-IDF:  61%|██████▏   | 79341/129036 [00:03<00:02, 22981.67it/s]\n",
      "\n",
      "Generating TF-IDF:  63%|██████▎   | 81642/129036 [00:03<00:02, 22959.69it/s]\n",
      "\n",
      "Generating TF-IDF:  65%|██████▌   | 83948/129036 [00:03<00:01, 22932.26it/s]\n",
      "\n",
      "Generating TF-IDF:  67%|██████▋   | 86265/129036 [00:03<00:01, 22986.66it/s]\n",
      "\n",
      "Generating TF-IDF:  69%|██████▊   | 88569/129036 [00:03<00:01, 22988.37it/s]\n",
      "\n",
      "Generating TF-IDF:  70%|███████   | 90870/129036 [00:03<00:01, 22950.56it/s]\n",
      "\n",
      "Generating TF-IDF:  72%|███████▏  | 93166/129036 [00:04<00:01, 22325.25it/s]\n",
      "\n",
      "Generating TF-IDF:  74%|███████▍  | 95504/129036 [00:04<00:01, 22592.41it/s]\n",
      "\n",
      "Generating TF-IDF:  76%|███████▌  | 97878/129036 [00:04<00:01, 22915.62it/s]\n",
      "\n",
      "Generating TF-IDF:  78%|███████▊  | 100216/129036 [00:04<00:01, 22993.65it/s]\n",
      "\n",
      "Generating TF-IDF:  79%|███████▉  | 102518/129036 [00:04<00:01, 22974.15it/s]\n",
      "\n",
      "Generating TF-IDF:  81%|████████▏ | 104866/129036 [00:04<00:01, 23122.79it/s]\n",
      "\n",
      "Generating TF-IDF:  83%|████████▎ | 107180/129036 [00:04<00:00, 23026.15it/s]\n",
      "\n",
      "Generating TF-IDF:  85%|████████▍ | 109484/129036 [00:04<00:00, 22975.80it/s]\n",
      "\n",
      "Generating TF-IDF:  87%|████████▋ | 111803/129036 [00:04<00:00, 22987.02it/s]\n",
      "\n",
      "Generating TF-IDF:  88%|████████▊ | 114160/129036 [00:04<00:00, 23129.03it/s]\n",
      "\n",
      "Generating TF-IDF:  90%|█████████ | 116474/129036 [00:05<00:00, 23029.26it/s]\n",
      "\n",
      "Generating TF-IDF:  92%|█████████▏| 118778/129036 [00:05<00:00, 23010.79it/s]\n",
      "\n",
      "Generating TF-IDF:  94%|█████████▍| 121080/129036 [00:05<00:00, 22919.31it/s]\n",
      "\n",
      "Generating TF-IDF:  96%|█████████▌| 123373/129036 [00:07<00:01, 3853.73it/s] \n",
      "\n",
      "Generating TF-IDF:  97%|█████████▋| 125687/129036 [00:07<00:00, 5141.44it/s]\n",
      "\n",
      "Generating TF-IDF: 100%|██████████| 129036/129036 [00:07<00:00, 17770.84it/s]\n",
      "\n",
      "\n",
      "Training topic models::   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 topics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training topic models::  20%|██        | 1/5 [01:15<05:01, 75.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 topics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training topic models::  40%|████      | 2/5 [02:40<04:03, 81.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 topics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training topic models::  60%|██████    | 3/5 [04:17<02:56, 88.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 topics\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "with Live(dir='../cross_validation', report='html') as live:\n",
    "    for fold, (train, test) in tqdm(enumerate(kf.split(procd_df)), desc=f'Folds:'):\n",
    "        print(f'Fold {fold}')\n",
    "        train_procd_df = procd_df.iloc[train]\n",
    "        test_procd_df = procd_df.iloc[test]\n",
    "\n",
    "        for procd_text in tqdm(procd_texts, desc=f'Preprocessed Text:'):\n",
    "            print(procd_text)\n",
    "            # Load preprocessed text data\n",
    "            train_procd_data = train_procd_df[procd_text].progress_apply(lambda x: eval(x))\n",
    "            train_procd_data = train_procd_data[train_procd_data.progress_apply(lambda row: len(row) > 0)]\n",
    "\n",
    "            test_procd_data = test_procd_df[procd_text].progress_apply(lambda x: eval(x))\n",
    "            test_procd_data = test_procd_data[test_procd_data.progress_apply(lambda row: len(row) > 0)]\n",
    "            \n",
    "            # Extract features from the training data\n",
    "            train_num_docs, _, procd_data_bigram, dictionary, train_bow_corpus, train_tfidf_corpus = feature_engineering(\n",
    "                procd_data = train_procd_data,\n",
    "                ngram = ngram,\n",
    "                bert = False,\n",
    "                bert_pretrained_model = None,\n",
    "                RANDOM_SEED = RANDOM_SEED\n",
    "            )\n",
    "\n",
    "            # Extract features from the test data\n",
    "            #_, _, _, _, test_bow_corpus, test_tfidf_corpus = feature_engineering(\n",
    "            #    procd_data = test_procd_data,\n",
    "            #    ngram = ngram,\n",
    "            #    bert = False,\n",
    "            #    bert_pretrained_model = None,\n",
    "            #    RANDOM_SEED = RANDOM_SEED\n",
    "            #)\n",
    "            \n",
    "            for num_topics in tqdm(nums_topics, desc=f'Training topic models:'):\n",
    "                if (num_topics <= 12) and (procd_text == 'lemma_wo_stpwrd'): continue\n",
    "                print(f'{num_topics} topics')\n",
    "                # Train the topic model\n",
    "                if feature == 'bow': train_corpus = train_bow_corpus\n",
    "                elif feature == 'tfidf': train_corpus = train_tfidf_corpus\n",
    "                else: raise ValueError(f'Unknown feature: {feature}')\n",
    "\n",
    "                topic_model, perplexity, coherence = topic_modeling(\n",
    "                    procd_data_bigram, train_corpus, dictionary, topic_modeling_algorithm, num_topics, RANDOM_SEED\n",
    "                )\n",
    "\n",
    "                live.log_param('Preprocessed Text', procd_text)\n",
    "                live.log_param('ngram', ngram)\n",
    "                live.log_param('Feature', feature)\n",
    "                live.log_param('Topic Modeling Algorithm', topic_modeling_algorithm)\n",
    "                live.log_param('Num of Topics', num_topics)\n",
    "\n",
    "                live.log_metric('Fold', fold)\n",
    "                live.log_metric('Num of Docs (Train)', train_num_docs)\n",
    "                live.log_metric('Coherence (Train)', coherence)\n",
    "                if perplexity is not None: live.log_metric('Perplexity (Train)', perplexity)\n",
    "\n",
    "                # Evaluate the model\n",
    "                #if feature == 'bow': test_corpus = test_bow_corpus\n",
    "                #elif feature == 'tfidf': test_corpus = test_tfidf_corpus\n",
    "                #else: raise ValueError(f'Unknown feature: {feature}')\n",
    "\n",
    "                # Calculate Coherence score\n",
    "                coherence_model = CoherenceModel(\n",
    "                    model=topic_model,\n",
    "                    texts=test_procd_data.tolist(),\n",
    "                    #corpus=test_corpus,\n",
    "                    dictionary=dictionary,\n",
    "                    coherence='c_v',\n",
    "                    #coherence='u_mass',\n",
    "                    processes=-1\n",
    "                )\n",
    "                coherence = coherence_model.get_coherence()\n",
    "                live.log_metric('Coherence (Test)', coherence)\n",
    "\n",
    "                live.next_step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
